{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"06_28_최종확인.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"155032b0f24c40c8a5aa8a3f47236892":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_923bce43ac3946038fbb723967a5e681","IPY_MODEL_3bf221ddc93e4aa0a9ec8915fe94657e","IPY_MODEL_7926e2782346438c80176f944189ab75"],"layout":"IPY_MODEL_6ea3a505442c4637a8242f3b4b4f28ce"}},"923bce43ac3946038fbb723967a5e681":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6109570f086419486f6ef6919b7807a","placeholder":"​","style":"IPY_MODEL_31b87208f65444d086429f1a1837890f","value":"100%"}},"3bf221ddc93e4aa0a9ec8915fe94657e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb90a97e41664ef18b36e56b854deaac","max":102530333,"min":0,"orientation":"horizontal","style":"IPY_MODEL_73d1c2d711fe4b4eb3ad969ea3956f67","value":102530333}},"7926e2782346438c80176f944189ab75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61286968d27a4e19ab57d15c7c64a399","placeholder":"​","style":"IPY_MODEL_89e6bc6797c245c88940250e8b83e11a","value":" 97.8M/97.8M [00:00&lt;00:00, 170MB/s]"}},"6ea3a505442c4637a8242f3b4b4f28ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6109570f086419486f6ef6919b7807a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31b87208f65444d086429f1a1837890f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb90a97e41664ef18b36e56b854deaac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73d1c2d711fe4b4eb3ad969ea3956f67":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"61286968d27a4e19ab57d15c7c64a399":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89e6bc6797c245c88940250e8b83e11a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["# Install requirements\n","!pip install fastapi\n","!pip install python-multipart\n","!pip install uvicorn\n","!pip install nest-asyncio\n","!pip install pyngrok\n","!pip install pymongo\n","!pip install pymongo[srv]\n","!pip install bcrypt\n","!pip install python-jose\n","!pip install passlib"],"metadata":{"id":"FZN8S0Famn7A","executionInfo":{"status":"ok","timestamp":1655709522004,"user_tz":-540,"elapsed":37484,"user":{"displayName":"Jung Lee","userId":"06037823346470885325"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"47388edd-b2ea-41eb-9a1e-2f905b3242b3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fastapi\n","  Downloading fastapi-0.78.0-py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 2.0 MB/s \n","\u001b[?25hRequirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.7/dist-packages (from fastapi) (1.8.2)\n","Collecting starlette==0.19.1\n","  Downloading starlette-0.19.1-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n","\u001b[?25hCollecting anyio<5,>=3.4.0\n","  Downloading anyio-3.6.1-py3-none-any.whl (80 kB)\n","\u001b[K     |████████████████████████████████| 80 kB 9.7 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from starlette==0.19.1->fastapi) (4.1.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio<5,>=3.4.0->starlette==0.19.1->fastapi) (2.10)\n","Collecting sniffio>=1.1\n","  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n","Installing collected packages: sniffio, anyio, starlette, fastapi\n","Successfully installed anyio-3.6.1 fastapi-0.78.0 sniffio-1.2.0 starlette-0.19.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting python-multipart\n","  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from python-multipart) (1.15.0)\n","Building wheels for collected packages: python-multipart\n","  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=800784a16e4e53dfdfd0740b28185e8d15578e914bf757c195547db17bcc2ca7\n","  Stored in directory: /root/.cache/pip/wheels/2c/41/7c/bfd1c180534ffdcc0972f78c5758f89881602175d48a8bcd2c\n","Successfully built python-multipart\n","Installing collected packages: python-multipart\n","Successfully installed python-multipart-0.0.5\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting uvicorn\n","  Downloading uvicorn-0.17.6-py3-none-any.whl (53 kB)\n","\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from uvicorn) (4.1.1)\n","Collecting asgiref>=3.4.0\n","  Downloading asgiref-3.5.2-py3-none-any.whl (22 kB)\n","Collecting h11>=0.8\n","  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 6.7 MB/s \n","\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from uvicorn) (7.1.2)\n","Installing collected packages: h11, asgiref, uvicorn\n","Successfully installed asgiref-3.5.2 h11-0.13.0 uvicorn-0.17.6\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (1.5.5)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyngrok\n","  Downloading pyngrok-5.1.0.tar.gz (745 kB)\n","\u001b[K     |████████████████████████████████| 745 kB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (3.13)\n","Building wheels for collected packages: pyngrok\n","  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyngrok: filename=pyngrok-5.1.0-py3-none-any.whl size=19007 sha256=f9103ae0813aafb5fb36eff537d2837d03bc55ca4a0f720562c049140d5031e3\n","  Stored in directory: /root/.cache/pip/wheels/bf/e6/af/ccf6598ecefecd44104069371795cb9b3afbcd16987f6ccfb3\n","Successfully built pyngrok\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-5.1.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (4.1.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pymongo[srv] in /usr/local/lib/python3.7/dist-packages (4.1.1)\n","Collecting dnspython<3.0.0,>=1.16.0\n","  Downloading dnspython-2.2.1-py3-none-any.whl (269 kB)\n","\u001b[K     |████████████████████████████████| 269 kB 5.4 MB/s \n","\u001b[?25hInstalling collected packages: dnspython\n","Successfully installed dnspython-2.2.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting bcrypt\n","  Downloading bcrypt-3.2.2-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 881 kB/s \n","\u001b[?25hRequirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt) (2.21)\n","Installing collected packages: bcrypt\n","Successfully installed bcrypt-3.2.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting python-jose\n","  Downloading python_jose-3.3.0-py2.py3-none-any.whl (33 kB)\n","Collecting ecdsa!=0.15\n","  Downloading ecdsa-0.17.0-py2.py3-none-any.whl (119 kB)\n","\u001b[K     |████████████████████████████████| 119 kB 8.4 MB/s \n","\u001b[?25hRequirement already satisfied: rsa in /usr/local/lib/python3.7/dist-packages (from python-jose) (4.8)\n","Requirement already satisfied: pyasn1 in /usr/local/lib/python3.7/dist-packages (from python-jose) (0.4.8)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from ecdsa!=0.15->python-jose) (1.15.0)\n","Installing collected packages: ecdsa, python-jose\n","Successfully installed ecdsa-0.17.0 python-jose-3.3.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting passlib\n","  Downloading passlib-1.7.4-py2.py3-none-any.whl (525 kB)\n","\u001b[K     |████████████████████████████████| 525 kB 5.4 MB/s \n","\u001b[?25hInstalling collected packages: passlib\n","Successfully installed passlib-1.7.4\n"]}]},{"cell_type":"code","source":["from fastapi import FastAPI, HTTPException, Depends, Request,status, File, UploadFile\n","from typing import List\n","from hashing import Hash\n","from jwttoken import create_access_token\n","from oauth import get_current_user, get_current_active_user\n","from models import User\n","from fastapi.security import OAuth2PasswordRequestForm\n","from fastapi.middleware.cors import CORSMiddleware\n","from config import db\n","import uvicorn\n","\n","\n","#from PIL import Image\n","from pyngrok import ngrok\n","import nest_asyncio"],"metadata":{"id":"3EAtJdED-ZZn","executionInfo":{"status":"ok","timestamp":1655709572666,"user_tz":-540,"elapsed":682,"user":{"displayName":"Jung Lee","userId":"06037823346470885325"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# for dohoon's code\n","\n","import os\n","import imutils\n","import numpy as np\n","import cv2\n","from PIL import Image\n","import matplotlib.patches as patches\n","import skimage\n","from skimage import io, transform\n"],"metadata":{"id":"TvLX6J93pPKO","executionInfo":{"status":"ok","timestamp":1655709575718,"user_tz":-540,"elapsed":938,"user":{"displayName":"Jung Lee","userId":"06037823346470885325"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import torchvision.models as models\n","import torch\n","import torch.nn as nn\n","from torchvision import transforms\n","\n","import matplotlib.pyplot as plt\n","from keras.preprocessing.image import load_img \n","\n","\n","import collections\n","from sklearn.cluster import KMeans\n","from sklearn.cluster import DBSCAN"],"metadata":{"id":"oBaARnGYtJX1","executionInfo":{"status":"ok","timestamp":1655709584095,"user_tz":-540,"elapsed":6988,"user":{"displayName":"Jung Lee","userId":"06037823346470885325"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#cropping\n","\n","def video_partition():\n","    count = []\n","    for i in range(1, 100):\n","        filepath = '/content/%d.mp4' % i\n","        if os.path.isfile(filepath):\n","            video = cv2.VideoCapture(filepath)\n","\n","            if not video.isOpened():\n","                print(\"Could not Open :\", filepath)\n","                exit(0)\n","\n","            length = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n","            width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n","            height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","            fps = video.get(cv2.CAP_PROP_FPS)\n","\n","            cnt = 0\n","\n","            while(video.isOpened()):\n","                if (cnt + 1) * (int)(fps) > length:\n","                    break \n","                ret, image = video.read()\n","                if(int(video.get(1)) % (int)(fps) == 0):\n","                    createFolder(\"/content/video%d\" % i)\n","                    cv2.imwrite(\"/content/video%d/frame%d.png\" % (i, cnt), image)\n","\n","                    cnt += 1\n","            video.release()\n","        else:\n","            break\n","        count.append(cnt)\n","\n","    return count, i - 1\n","    \n","def load_image(image_path):\n","    img = skimage.img_as_float(io.imread(image_path))\n","    if len(img.shape) == 2:\n","        img = np.array([img, img, img]).swapaxes(0, 2)\n","    return img\n","\n","def rescale(img, input_height, input_width):\n","    aspect = img.shape[1] / float(img.shape[0])\n","    if (aspect > 1):\n","    # landscape orientation - wide image\n","        res = int(aspect * input_height)\n","        imgScaled = transform.resize(img, (input_width, res))\n","    if (aspect < 1):\n","        # portrait orientation - tall image\n","        res = int(input_width / aspect)\n","        imgScaled = transform.resize(img, (res, input_height))\n","    if (aspect == 1):\n","        imgScaled = transform.resize(img, (input_width, input_height))\n","    return imgScaled\n","  \n","def normalize(img, mean=128, std=128):\n","    img = (img * 256 - mean) / std\n","    return img\n","\n","def crop_center(img, cropx, cropy):\n","    y, x, c = img.shape\n","    startx = x // 2 - (cropx // 2)\n","    starty = y // 2 - (cropy // 2)\n","    return img[starty:starty + cropy, startx:startx + cropx]\n","\n","def createFolder(directory):\n","    try:\n","        if not os.path.exists(directory):\n","            os.makedirs(directory)\n","    except OSError:\n","        print('Error:Creating directory.' + directory)\n","        \n","def prepare(img_uri):\n","        img = load_image(img_uri)\n","        img = rescale(img, 300, 300)\n","        img = transform.resize(img, (300, 300))\n","        img = normalize(img)\n","        return img"],"metadata":{"id":"G5ZcOMEynfxL","executionInfo":{"status":"ok","timestamp":1655709585918,"user_tz":-540,"elapsed":351,"user":{"displayName":"Jung Lee","userId":"06037823346470885325"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def ssd(target):\n","    k, v = video_partition()\n","    import torch\n","    device = torch.device('cpu')\n","\n","    ssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd')\n","    utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')\n","\n","\n","    ssd_model.to('cuda')\n","    ssd_model.eval()\n","\n","    for j in range(1, v + 1):   \n","        count = 1    \n","        uris = list()\n","        for i in range(k[j - 1]):\n","            uris.append('/content/video%d/frame%d.png' % (j, i))\n","\n","        inputs = [prepare(uri) for uri in uris]\n","        tensor = utils.prepare_tensor(inputs)\n","\n","        with torch.no_grad():\n","            detections_batch = ssd_model(tensor)\n","\n","        results_per_input = utils.decode_results(detections_batch)\n","        best_results_per_input = [utils.pick_best(results, 0.70) for results in results_per_input]\n","        classes_to_labels = utils.get_coco_object_dictionary()\n","        createFolder(\"/content/result%d\" % j)\n","\n","        i = 1\n","\n","        for item in target:\n","          t = cv2.imread(f'/content/{item}')\n","          cv2.imwrite(f'/content/result{j}/{item}', t)\n","          i = i + 1\n","\n","        for image_idx in range(len(best_results_per_input)):\n","            tmp = plt.imread('/content/video%d/frame%d.png' % (j, image_idx))\n","            image = inputs[image_idx] / 2 + 0.5\n","            bboxes, classes, confidences = best_results_per_input[image_idx]\n","            for idx in range(len(bboxes)):\n","                left, bot, right, top = bboxes[idx]\n","                x, y, w, h = [val * 300 for val in [left, bot, right - left, top - bot]]\n","                if classes_to_labels[classes[idx] - 1] == 'person':         \n","                    tmp = rescale(tmp, 300, 300)\n","                    tmp = transform.resize(tmp, (300, 300))\n","                    if y < 0:\n","                        y = 0\n","                    if x < 0:\n","                        x = 0\n","                    cropped = tmp[int(y):int(y+h), int(x):int(x+w)]\n","                    plt.imsave(\"/content/result%d/%d.png\" % (j, count), cropped)\n","                    count += 1"],"metadata":{"id":"T3LgZGDuoPV6","executionInfo":{"status":"ok","timestamp":1655709586872,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jung Lee","userId":"06037823346470885325"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def GetDLModel():\n","    # 모델 불러와서 일부 키 값 resnet50 model에 맞게 수정\n","    # 아래 torch.load에서 모델을 저장한 경로만 바뀌면 됩니다.\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n","\n","    checkpoint2 = torch.load(\n","        '/content/resnet50_market_xent.pth.tar', map_location=device, encoding='latin1')\n","    checkpoint2['state_dict']['fc.weight'] = checkpoint2['state_dict'].pop(\n","        'classifier.weight')\n","    checkpoint2['state_dict']['fc.bias'] = checkpoint2['state_dict'].pop(\n","        'classifier.bias')\n","\n","    # 기존의 resnet50을 market1501을 학습 시킨 모델과 출력층이 동일하게 구성\n","    res2 = models.resnet50()\n","    x = res2.fc.weight\n","    x = torch.narrow(x, 0, 0, 751)\n","    y = res2.fc.bias\n","    y = torch.narrow(y, 0, 0, 751)\n","\n","    res2.fc.weight = nn.Parameter(x)\n","    res2.fc.bias = nn.Parameter(y)\n","    res2.fc.out_features = 751\n","\n","    # 모델 덮어 씌우기\n","    res2.load_state_dict(checkpoint2['state_dict'])\n","    res2.to(device)  # 가중치를 GPU 계산과 CPU 계산 중 하나로 통일\n","\n","    return res2\n","\n","def getImages():\n","    # 이미지 폴더에서 이미지 셋 리스트에 저장\n","\n","    path = '/content/result1'\n","    os.chdir(path)\n","\n","    images = []\n","\n","    # 이미지 파일 리스트에 삽입\n","    with os.scandir(path) as files:\n","        for file in files:\n","            if file.name.endswith('.png'):\n","                images.append(file.name)\n","    return images\n","\n","class FeatureExtractor(nn.Module):\n","    def __init__(self, model):\n","        super(FeatureExtractor, self).__init__()\n","        self.conv1 = model.conv1\n","        self.bn1 = model.bn1\n","        self.relu = model.relu\n","        self.maxpool = model.maxpool\n","        self.layer1 = model.layer1\n","        self.layer2 = model.layer2\n","        self.layer3 = model.layer3\n","        self.layer4 = model.layer4\n","        self.global_avgpool = model.avgpool\n","        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n","        return\n","\n","    def featuremaps(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        return x\n","\n","    def forward(self, x):\n","        f = self.featuremaps(x)\n","        v = self.global_avgpool(f)\n","        v = v.view(v.size(0), -1)\n","        v = self.pool(v)\n","        v = self.pool(v)\n","        v = self.pool(v)\n","        v = self.pool(v)\n","        return v\n","\n","# 이미지 특징 추출 함수\n","\n","def extracting_feature(model, images, target_name, transform):\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n","    features_ = []\n","    extract_feature = FeatureExtractor(model)\n","    for i in range(len(images)):\n","        if i == len(images):\n","            break\n","\n","        path = os.path.join('/content/result1', images[i])\n","        img = load_img(path, target_size=(224, 224))\n","        img = np.array(img)\n","        img = transform(img)\n","        img = img.reshape(1, 3, 224, 224)\n","        img = img.to(device)\n","        with torch.no_grad():\n","            feature = extract_feature(img)\n","        features_.append(feature.cpu().detach().numpy().reshape(-1))\n","    return features_\n","\n","\n","def clusters(feat, n_clusters=10):\n","    kmeans = KMeans(n_clusters=n_clusters, init='k-means++', n_init=5, max_iter=300)\n","    kmeans.fit(feat)\n","    result = kmeans.labels_\n","    labels = np.unique(result)\n","    return result, labels\n","\n","# 이미지 transform 구성\n","def get_transform():\n","    transform = transforms.Compose([\n","        transforms.ToPILImage(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n","    return transform\n","\n","\n","def play(n_cluster=3, image_name=['target.png']):\n","    target_name = image_name\n","    MyResnet = GetDLModel()\n","    zepeto = getImages()\n","    trans = get_transform()\n","    features = extracting_feature(MyResnet, zepeto, target_name, trans)\n","    features = np.array(features)\n","    (res, labels) = clusters(features, n_cluster)\n","\n","    groups = {}\n","    for file, cluster in zip(zepeto, res):\n","        if cluster not in groups.keys():\n","            groups[cluster] = []\n","            groups[cluster].append(file)\n","        else:\n","            groups[cluster].append(file)\n","    count = 0\n","    for i in range(len(labels)):\n","        flag = 0\n","        for target in target_name:\n","            if target in groups[i]:\n","                flag = 1\n","        if flag == 0:\n","            count += len(groups[i])\n","    return count"],"metadata":{"id":"N89ZzNOttce1","executionInfo":{"status":"ok","timestamp":1655709588548,"user_tz":-540,"elapsed":340,"user":{"displayName":"Jung Lee","userId":"06037823346470885325"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["app = FastAPI()\n","origins = [\n","    \"http://localhost\",\n","    \"http://localhost:3000\",\n","    \"http://localhost:8080\",\n","]\n","app.add_middleware(\n","    CORSMiddleware,\n","    allow_origins=origins,\n","    allow_credentials=True,\n","    allow_methods=[\"*\"],\n","    allow_headers=[\"*\"],\n",")"],"metadata":{"id":"uEPn9UURmrzc","executionInfo":{"status":"ok","timestamp":1655709589806,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jung Lee","userId":"06037823346470885325"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["@app.get(\"/\")\n","def read_root():\n","    return {\"Hello\": \"World\"}\n","\n","@app.post(\"/files/\")\n","async def create_files(current_user:User = Depends(get_current_user),files: List[bytes] = File(...)):\n","    return {\"file_sizes\": [len(file) for file in files]}\n","\n","\n","@app.post(\"/uploadfiles\")\n","async def create_upload_files(num : int, current_user:User = Depends(get_current_user),  files: List[UploadFile] = File(...) ):\n","    UPLOAD_DIRECTORY = \"./\"\n","    realname = current_user.username\n","\n","    if num != current_user.target_num:\n","        db[\"users\"].update_one({'username': realname}, {'$set': {'target_num': num}})\n","\n","    for file in files:\n","        contents = await file.read()\n","        with open(os.path.join(UPLOAD_DIRECTORY, file.filename), \"wb\") as fp:\n","            fp.write(contents)\n","\n","    for file in files:\n","        if(file.filename[-4:] == \".mp4\"):\n","            if(current_user.filename == \"video.mp4\"):\n","                db[\"users\"].update_one({'username': realname}, {'$set': {'filename': file.filename}})\n","\n","        elif(file.filename[-4:] == \".png\"):\n","            if(current_user.targetname == \"default.png\"):\n","                db[\"users\"].update_one({'username': realname}, {'$set': {'targetname': file.filename}})\n","\n","    return {\"filenames\": [file.filename for file in files]}\n","\n","@app.post('/register')\n","async def create_user(request:User):\n","\thashed_pass = Hash.bcrypt(request.password)\n","\tuser_object = dict(request)\n","\tuser_object[\"password\"] = hashed_pass\n","\tuser_id = db[\"users\"].insert_one(user_object)\n","\treturn {\"register\":\"completed\"}\n","\n","@app.post('/login')\n","async def login(request:OAuth2PasswordRequestForm = Depends()):\n","\tuser = db[\"users\"].find_one({\"username\":request.username})\n","\tif not user:\n","\t\traise HTTPException(status_code=status.HTTP_404_NOT_FOUND,detail = f'No user found with this {request.username} username')\n","\tif not Hash.verify(user[\"password\"],request.password):\n","\t\traise HTTPException(status_code=status.HTTP_404_NOT_FOUND,detail = f'Wrong Username or password')\n","\taccess_token = create_access_token(data={\"sub\": user[\"username\"] })\n","\treturn {\"access_token\": access_token, \"token_type\": \"bearer\"}\n","\n","@app.put(\"/play\")\n","async def algo(current_user:User = Depends(get_current_active_user)):\n","#algorithm\n","\n","    list_name = []\n","    list_name.append(current_user.targetname)\n","    numb = current_user.target_num\n","\n","    ssd(list_name)\n","    cnt = play(numb,list_name)\n","    print(cnt)\n","    score = 0\n","    if cnt < 20:\n","        score = 20\n","    elif cnt < 50:\n","        score = 50\n","    elif cnt < 80:\n","        score = 80\n","    elif cnt < 100:\n","        score = 100\n","    elif cnt < 150:\n","        score = 150\n","    else:\n","        score = 200\n","#update\n","    realname = current_user.username\n","    user_score = current_user.score + score\n","    db[\"users\"].update_one({'username': realname}, {'$set': {'score': user_score}})\n","\n","    return {cnt : score}"],"metadata":{"id":"xY1C739kmyIo","executionInfo":{"status":"ok","timestamp":1655709590993,"user_tz":-540,"elapsed":3,"user":{"displayName":"Jung Lee","userId":"06037823346470885325"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["auth_token = \"29vVaP7lvt3oLllnrWLYmOVJrUn_5x7Rdz1f4HkEUkLJm2t15\" #@param {type:\"string\"}\n","# Since we can't access Colab notebooks IP directly we'll use\n","# ngrok to create a public URL for the server via a tunnel\n","\n","# Authenticate ngrok\n","# https://dashboard.ngrok.com/signup\n","# Then go to the \"Your Authtoken\" tab in the sidebar and copy the API key\n","os.system(f\"ngrok authtoken {auth_token}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q8_QZ4Y1nSvZ","executionInfo":{"status":"ok","timestamp":1655709593110,"user_tz":-540,"elapsed":1113,"user":{"displayName":"Jung Lee","userId":"06037823346470885325"}},"outputId":"8cd3b20b-268d-4efd-8c4b-22cbf8cd6785"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# Create tunnel\n","public_url = ngrok.connect(8000, port='8000', bind_tls=True)\n","# Check if it exists\n","!ps aux | grep ngrok"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UNug5ZUwnSx9","executionInfo":{"status":"ok","timestamp":1655709594746,"user_tz":-540,"elapsed":412,"user":{"displayName":"Jung Lee","userId":"06037823346470885325"}},"outputId":"1ef62ba5-5b00-42e3-a9bd-29ac6e94808a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["root         346 18.0  0.1 724156 21460 ?        Sl   07:19   0:00 /usr/local/lib/python3.7/dist-packages/pyngrok/bin/ngrok start --none --log=stdout\n","root         356  0.0  0.0  39200  6668 ?        S    07:19   0:00 /bin/bash -c ps aux | grep ngrok\n","root         358  0.0  0.0  38572  5508 ?        S    07:19   0:00 grep ngrok\n"]}]},{"cell_type":"code","source":["# Allow for asyncio to work within the Jupyter notebook cell\n","nest_asyncio.apply()\n","\n","# Run the FastAPI app using uvicorn\n","print(public_url)\n","uvicorn.run(app)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":614,"referenced_widgets":["155032b0f24c40c8a5aa8a3f47236892","923bce43ac3946038fbb723967a5e681","3bf221ddc93e4aa0a9ec8915fe94657e","7926e2782346438c80176f944189ab75","6ea3a505442c4637a8242f3b4b4f28ce","c6109570f086419486f6ef6919b7807a","31b87208f65444d086429f1a1837890f","cb90a97e41664ef18b36e56b854deaac","73d1c2d711fe4b4eb3ad969ea3956f67","61286968d27a4e19ab57d15c7c64a399","89e6bc6797c245c88940250e8b83e11a"]},"id":"GznwjQeanS0e","outputId":"7ee4a257-51f6-409e-d14e-1c427fa065b4","executionInfo":{"status":"ok","timestamp":1655710922395,"user_tz":-540,"elapsed":1326336,"user":{"displayName":"Jung Lee","userId":"06037823346470885325"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["NgrokTunnel: \"https://5537-34-136-174-10.ngrok.io\" -> \"http://localhost:8000\"\n"]},{"output_type":"stream","name":"stderr","text":["INFO:     Started server process [72]\n","INFO:     Waiting for application startup.\n","INFO:     Application startup complete.\n","INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:     211.108.54.19:0 - \"GET / HTTP/1.1\" 200 OK\n","INFO:     211.108.54.19:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n","INFO:     211.108.54.19:0 - \"GET / HTTP/1.1\" 200 OK\n","INFO:     211.108.54.19:0 - \"GET /docs HTTP/1.1\" 200 OK\n","INFO:     211.108.54.19:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n","INFO:     211.108.54.19:0 - \"POST /register HTTP/1.1\" 200 OK\n","INFO:     211.108.54.19:0 - \"POST /register HTTP/1.1\" 200 OK\n","INFO:     211.108.54.19:0 - \"POST /login HTTP/1.1\" 200 OK\n","INFO:     211.108.54.19:0 - \"POST /uploadfiles?num=3 HTTP/1.1\" 200 OK\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/NVIDIA/DeepLearningExamples/archive/torchhub.zip\" to /root/.cache/torch/hub/torchhub.zip\n","/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:14: UserWarning: pytorch_quantization module not found, quantization will not be available\n","  \"pytorch_quantization module not found, quantization will not be available\"\n","/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:18: UserWarning: pytorch_quantization module not found, quantization will not be available\n","  \"pytorch_quantization module not found, quantization will not be available\"\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/97.8M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"155032b0f24c40c8a5aa8a3f47236892"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Downloading checkpoint from https://api.ngc.nvidia.com/v2/models/nvidia/ssd_pyt_ckpt_amp/versions/20.06.0/files/nvidia_ssdpyt_amp_200703.pt\n","Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"]},{"output_type":"stream","name":"stdout","text":["Downloading COCO annotations.\n","Downloading finished.\n","83\n","INFO:     211.108.54.19:0 - \"PUT /play HTTP/1.1\" 200 OK\n"]},{"output_type":"stream","name":"stderr","text":["INFO:     Shutting down\n","INFO:     Waiting for application shutdown.\n","INFO:     Application shutdown complete.\n","INFO:     Finished server process [72]\n"]}]},{"cell_type":"code","source":["# Kill tunnel\n","#ngrok.kill()\n","\n","ngrok.disconnect(public_url=public_url)"],"metadata":{"id":"miRwkaqBnbcb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"u07XcbwIslUL"},"execution_count":null,"outputs":[]}]}